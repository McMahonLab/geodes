# gff_test.sub
#
#
# Specify the HTCondor Universe
universe = vanilla
log = gff_test_$(Cluster).log
error = gff_test_$(Cluster)_$(Process).err
requirements = (OpSys == "LINUX") && (Arch == "X86_64") && (Target.HasGluster == true)
#
# Specify your executable, arguments, and a file for HTCondor to store standard
#  output.
executable = /home/amlinz/executables/gff_test.sh
arguments = $(samplename)
output = gff_test_$(Cluster).out
#
# Specify that HTCondor should transfer files to and from the
#  computer where each job runs.
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_input_files = zipped/python.tar.gz,zipped/genometools.tar.gz,scripts/metaG_parsing.py,gff_test/$(samplename)
transfer_output_files = CDS.$(samplename).fna,$(samplename).table.txt
#
# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
# Requirements = (Target.HasGluster == true)
request_cpus = 1
request_memory = 4GB
request_disk = 2GB
#
# Tell HTCondor to run every fastq file in the provided list:
queue samplename from gff_test.txt

